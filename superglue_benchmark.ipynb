{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3045b9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command to free neuron core (forces Kernel restart)\n",
    "# import IPython\n",
    "# IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7c71892",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = 'images'\n",
    "\n",
    "RESIZE_IMAGE = True\n",
    "# RESIZE_DIMENSIONS = [968, 1296]\n",
    "RESIZE_DIMENSIONS = [1080, 1920]\n",
    "\n",
    "NUM_KEYPOINTS = 2000\n",
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e39696",
   "metadata": {},
   "source": [
    "# Input preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e364076",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7417c1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import pprint\n",
    "import sys\n",
    "\n",
    "sys.path.append('/home/ubuntu/SuperGluePretrainedNetwork')\n",
    "\n",
    "from models.superpoint import SuperPoint\n",
    "from models.superglue import SuperGlue\n",
    "from torch.utils.benchmark import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba80d398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on device cpu\n"
     ]
    }
   ],
   "source": [
    "# Disable gradient computation\n",
    "torch.set_grad_enabled(False)\n",
    "print(f\"Running inference on device {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ae773c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Help functions\n",
    "def group_image_files(folder):\n",
    "    \"\"\"Group image files in the given folder by their prefix.\"\"\"\n",
    "    files = os.listdir(IMAGE_FOLDER)\n",
    "    groups = {}\n",
    "    for file in files:\n",
    "        if '_' in file:\n",
    "            prefix = file.split('_')[0]\n",
    "        else:\n",
    "            prefix = 'no_underscore'\n",
    "            \n",
    "        if prefix not in groups:\n",
    "            groups[prefix] = []\n",
    "        groups[prefix].append(file)\n",
    "\n",
    "    return list(groups.values())\n",
    "\n",
    "def read_test_image(file_path, resize_image=False, resize_to_dimensions=[968, 1296]):\n",
    "    print(f\"Reading image from {file_path}\")\n",
    "    image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    print(f\"Original image size: {image.shape}\")\n",
    "    if resize_image:\n",
    "        image = cv2.resize(image.astype('float32'), (resize_to_dimensions[1], resize_to_dimensions[0]))\n",
    "        print(f\"Image resized to {image.shape}\")\n",
    "        # Save the resized image\n",
    "        original_folder_path = os.path.dirname(file_path)\n",
    "        parent_folder_path = os.path.dirname(original_folder_path)\n",
    "        resized_folder_path = os.path.join(parent_folder_path, 'image_resized')\n",
    "        os.makedirs(resized_folder_path, exist_ok=True)\n",
    "        file_name = os.path.basename(file_path)\n",
    "        resized_file_name = f\"resized_{resize_to_dimensions[0]}_{resize_to_dimensions[1]}_{file_name}\"\n",
    "        resized_file_path = os.path.join(resized_folder_path, resized_file_name)\n",
    "        cv2.imwrite(resized_file_path, image)\n",
    "        print(f\"Saved resized image to {resized_file_path}\")\n",
    "    else:\n",
    "        print(\"Not resizing image\")\n",
    "    return {\n",
    "        \"file_name\": file_path.split(\"/\")[-1],\n",
    "        'image': image,\n",
    "        'inp': torch.from_numpy(image/255.).float()[None, None].to(DEVICE)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "552441d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading image from images/IMG_9320.jpg\n",
      "Original image size: (3024, 4032)\n",
      "Image resized to (1080, 1920)\n",
      "Saved resized image to image_resized/resized_1080_1920_IMG_9320.jpg\n",
      "Reading image from images/IMG_9321.jpg\n",
      "Original image size: (3024, 4032)\n",
      "Image resized to (1080, 1920)\n",
      "Saved resized image to image_resized/resized_1080_1920_IMG_9321.jpg\n",
      "Reading image from images/IMG_9323.jpg\n",
      "Original image size: (3024, 4032)\n",
      "Image resized to (1080, 1920)\n",
      "Saved resized image to image_resized/resized_1080_1920_IMG_9323.jpg\n",
      "Reading image from images/IMG_9324.jpg\n",
      "Original image size: (3024, 4032)\n",
      "Image resized to (1080, 1920)\n",
      "Saved resized image to image_resized/resized_1080_1920_IMG_9324.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@5.552] global loadsave.cpp:1063 imwrite_ Unsupported depth image for selected encoder is fallbacked to CV_8U.\n"
     ]
    }
   ],
   "source": [
    "# Image Loading and Preprocessing\n",
    "test_groups = group_image_files(IMAGE_FOLDER)\n",
    "\n",
    "img1 = read_test_image(file_path=os.path.join(IMAGE_FOLDER, \"IMG_9320.jpg\"), resize_image=RESIZE_IMAGE, resize_to_dimensions=RESIZE_DIMENSIONS)\n",
    "img2 = read_test_image(file_path=os.path.join(IMAGE_FOLDER, \"IMG_9321.jpg\"), resize_image=RESIZE_IMAGE, resize_to_dimensions=RESIZE_DIMENSIONS)\n",
    "\n",
    "img3 = read_test_image(file_path=os.path.join(IMAGE_FOLDER, \"IMG_9323.jpg\"), resize_image=RESIZE_IMAGE, resize_to_dimensions=RESIZE_DIMENSIONS)\n",
    "img4 = read_test_image(file_path=os.path.join(IMAGE_FOLDER, \"IMG_9324.jpg\"), resize_image=RESIZE_IMAGE, resize_to_dimensions=RESIZE_DIMENSIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e2f652",
   "metadata": {},
   "source": [
    "## SuperPoint inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db3564fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SuperPoint model\n"
     ]
    }
   ],
   "source": [
    "super_point_model = SuperPoint( {\"max_keypoints\":NUM_KEYPOINTS}).eval().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60719035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process images with SuperPoint\n",
    "def process_image_with_superpoint(image):\n",
    "    \"\"\"Process an image with the SuperPoint model.\"\"\"\n",
    "    points = super_point_model({'image': image['inp']})\n",
    "    print(f\"\\n{image['file_name']}:\")\n",
    "    print(f\"\\tKey Points shape: {points['keypoints'][0].shape}\")\n",
    "    print(f\"\\tDescriptors shape: {points['descriptors'][0].shape}\")\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a506b789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IMG_9320.jpg:\n",
      "\tKey Points shape: torch.Size([2000, 2])\n",
      "\tDescriptors shape: torch.Size([256, 2000])\n",
      "\n",
      "IMG_9321.jpg:\n",
      "\tKey Points shape: torch.Size([2000, 2])\n",
      "\tDescriptors shape: torch.Size([256, 2000])\n",
      "\n",
      "IMG_9323.jpg:\n",
      "\tKey Points shape: torch.Size([2000, 2])\n",
      "\tDescriptors shape: torch.Size([256, 2000])\n",
      "\n",
      "IMG_9324.jpg:\n",
      "\tKey Points shape: torch.Size([2000, 2])\n",
      "\tDescriptors shape: torch.Size([256, 2000])\n"
     ]
    }
   ],
   "source": [
    "points_image_1 = process_image_with_superpoint(img1)\n",
    "points_image_2 = process_image_with_superpoint(img2)\n",
    "points_image_3 = process_image_with_superpoint(img3)\n",
    "points_image_4 = process_image_with_superpoint(img4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63130237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved superpoints outputs assets/superpoint_outputs/IMG_9320_2000_1080_1920.pt\n",
      "saved superpoints outputs assets/superpoint_outputs/IMG_9321_2000_1080_1920.pt\n",
      "saved superpoints outputs assets/superpoint_outputs/IMG_9323_2000_1080_1920.pt\n",
      "saved superpoints outputs assets/superpoint_outputs/IMG_9324_2000_1080_1920.pt\n"
     ]
    }
   ],
   "source": [
    "def save_superpoint_outputs(points, file_name, folder='assets/superpoint_outputs'):    \n",
    "    if not file_name.endswith('.pt'):\n",
    "        file_name += '.pt'\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    file_path = os.path.join(folder, file_name)\n",
    "    torch.save(points, file_path)\n",
    "    print(f\"saved superpoints outputs {file_path}\")\n",
    "\n",
    "for points_image, img in zip([points_image_1,points_image_2,points_image_3,points_image_4], [img1,img2,img3,img4]):\n",
    "    save_superpoint_outputs(points_image, f'{img[\"file_name\"].split(\".\")[0]}_{NUM_KEYPOINTS}_{img[\"image\"].shape[0]}_{img[\"image\"].shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dd8c6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points loaded from assets/superpoint_outputs/IMG_9320_2000_1080_1920.pt\n",
      "Points loaded from assets/superpoint_outputs/IMG_9321_2000_1080_1920.pt\n",
      "Points loaded from assets/superpoint_outputs/IMG_9323_2000_1080_1920.pt\n",
      "Points loaded from assets/superpoint_outputs/IMG_9324_2000_1080_1920.pt\n"
     ]
    }
   ],
   "source": [
    "def load_points_image(file_name='points_image_1', folder='assets/superpoint_outputs'):\n",
    "    if not file_name.endswith('.pt'):\n",
    "        file_name += '.pt'\n",
    "    \n",
    "    file_path = os.path.join(folder, file_name)    \n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"No file found at {file_path}\")\n",
    "    \n",
    "    points = torch.load(file_path)\n",
    "    print(f\"Points loaded from {file_path}\")\n",
    "    return points\n",
    "\n",
    "points_image_1 = load_points_image(f'{img1[\"file_name\"].split(\".\")[0]}_{NUM_KEYPOINTS}_{img1[\"image\"].shape[0]}_{img1[\"image\"].shape[1]}')\n",
    "points_image_2 = load_points_image(f'{img2[\"file_name\"].split(\".\")[0]}_{NUM_KEYPOINTS}_{img2[\"image\"].shape[0]}_{img2[\"image\"].shape[1]}')\n",
    "points_image_3 = load_points_image(f'{img3[\"file_name\"].split(\".\")[0]}_{NUM_KEYPOINTS}_{img3[\"image\"].shape[0]}_{img3[\"image\"].shape[1]}')\n",
    "points_image_4 = load_points_image(f'{img4[\"file_name\"].split(\".\")[0]}_{NUM_KEYPOINTS}_{img4[\"image\"].shape[0]}_{img4[\"image\"].shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb35275",
   "metadata": {},
   "source": [
    "## Prepare SuperGlue inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31e76450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def make_superglue_input(image_pairs):\n",
    "    \"\"\"\n",
    "    Create SuperGlue input for multiple pairs of images.\n",
    "    :param image_pairs: A list of tuples, each containing a pair of (superpoint_data, img_data)\n",
    "                        for two images to be matched.\n",
    "    :return: A dictionary with batched SuperGlue input.\n",
    "    \"\"\"\n",
    "\n",
    "    super_glue_input = {\n",
    "        'keypoints0': [],\n",
    "        'keypoints1': [],\n",
    "        'descriptors0': [],\n",
    "        'descriptors1': [],\n",
    "        'scores0': [],\n",
    "        'scores1': [],\n",
    "        'image0': [],\n",
    "        'image1': []\n",
    "    }\n",
    "\n",
    "    for (data1, img_1), (data2, img_2) in image_pairs:\n",
    "        super_glue_input['keypoints0'] += data1['keypoints']\n",
    "        super_glue_input['keypoints1'] += data2['keypoints']\n",
    "        super_glue_input['descriptors0']+= data1['descriptors']\n",
    "        super_glue_input['descriptors1']+= data2['descriptors']\n",
    "        super_glue_input['scores0']+= data1['scores']\n",
    "        super_glue_input['scores1']+= data2['scores']\n",
    "        super_glue_input['image0']+= img_1['inp']\n",
    "        super_glue_input['image1']+= img_2['inp']\n",
    "\n",
    "    # Concatenate all tensors along the batch dimension (dim=0)\n",
    "    for k in super_glue_input:\n",
    "        if isinstance(super_glue_input[k], (list, tuple)):\n",
    "            super_glue_input[k] = torch.stack(super_glue_input[k], dim=0)\n",
    "    for k in super_glue_input.keys():\n",
    "        print(f\"{k} shape: {super_glue_input[k].shape}\")\n",
    "        \n",
    "    return super_glue_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35f97d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch size 1 - Pair 1\n",
      "keypoints0 shape: torch.Size([1, 2000, 2])\n",
      "keypoints1 shape: torch.Size([1, 2000, 2])\n",
      "descriptors0 shape: torch.Size([1, 256, 2000])\n",
      "descriptors1 shape: torch.Size([1, 256, 2000])\n",
      "scores0 shape: torch.Size([1, 2000])\n",
      "scores1 shape: torch.Size([1, 2000])\n",
      "image0 shape: torch.Size([1, 1, 1080, 1920])\n",
      "image1 shape: torch.Size([1, 1, 1080, 1920])\n",
      "\n",
      "Batch size 1 - Pair 2\n",
      "keypoints0 shape: torch.Size([1, 2000, 2])\n",
      "keypoints1 shape: torch.Size([1, 2000, 2])\n",
      "descriptors0 shape: torch.Size([1, 256, 2000])\n",
      "descriptors1 shape: torch.Size([1, 256, 2000])\n",
      "scores0 shape: torch.Size([1, 2000])\n",
      "scores1 shape: torch.Size([1, 2000])\n",
      "image0 shape: torch.Size([1, 1, 1080, 1920])\n",
      "image1 shape: torch.Size([1, 1, 1080, 1920])\n"
     ]
    }
   ],
   "source": [
    "# batch size 1\n",
    "superglue_raw_input_bs1_1 = [((points_image_1, img1), (points_image_2, img2))] # pair 1 (img1 and img2)\n",
    "superglue_raw_input_bs1_2 = [((points_image_3, img3), (points_image_4, img4))] # pair 2 (img3 and img4)\n",
    "\n",
    "print(\"\\nBatch size 1 - Pair 1\")\n",
    "super_glue_input_bs1_1 = make_superglue_input(superglue_raw_input_bs1_1)\n",
    "print(\"\\nBatch size 1 - Pair 2\")\n",
    "super_glue_input_bs1_2 = make_superglue_input(superglue_raw_input_bs1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9e48d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch size 2 - Pair 1 & 2\n",
      "keypoints0 shape: torch.Size([2, 2000, 2])\n",
      "keypoints1 shape: torch.Size([2, 2000, 2])\n",
      "descriptors0 shape: torch.Size([2, 256, 2000])\n",
      "descriptors1 shape: torch.Size([2, 256, 2000])\n",
      "scores0 shape: torch.Size([2, 2000])\n",
      "scores1 shape: torch.Size([2, 2000])\n",
      "image0 shape: torch.Size([2, 1, 1080, 1920])\n",
      "image1 shape: torch.Size([2, 1, 1080, 1920])\n"
     ]
    }
   ],
   "source": [
    "# batch size 2\n",
    "superglue_raw_input_bs2 = [((points_image_1, img1), (points_image_2, img2)), ((points_image_3, img3), (points_image_4, img4))]\n",
    "\n",
    "print(\"\\nBatch size 2 - Pair 1 & 2\")\n",
    "super_glue_input_bs2 = make_superglue_input(superglue_raw_input_bs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42284fbe",
   "metadata": {},
   "source": [
    "## Benchmark Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04a3a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "def plot_matches(\n",
    "        img_0,\n",
    "        img_1,\n",
    "        kpts_0,\n",
    "        kpts_1,\n",
    "        matches_0,\n",
    "        scores_0,\n",
    "        num_keypoints,\n",
    "        hardware_type,\n",
    "    ):\n",
    "    image0 = img_0['image']\n",
    "    image1 = img_1['image']\n",
    "    kpts0 = kpts_0.cpu().numpy()\n",
    "    kpts1 = kpts_1.cpu().numpy()\n",
    "    mkpts0 = kpts0\n",
    "    text = []\n",
    "\n",
    "    mkpts1 = kpts1[matches_0.cpu().numpy()]\n",
    "    conf = scores_0.cpu()\n",
    "    color = cm.jet(conf)\n",
    "    filename=f'{img_0[\"file_name\"].split(\".\")[0]}_{img_1[\"file_name\"].split(\".\")[0]}_matches_{hardware_type}_{num_keypoints}_{img_0[\"image\"].shape[0]}_{img_0[\"image\"].shape[1]}'\n",
    "    \n",
    "    os.makedirs('assets/matches', exist_ok=True)\n",
    "    path = os.path.join('assets/matches', f'{filename}.png')\n",
    "    make_matching_plot(image0, image1, kpts0, kpts1, mkpts0, mkpts1, color, text, matches_0, path, opencv_display=False)\n",
    "\n",
    "# Visualize the matches.\n",
    "def make_matching_plot(image0, image1, kpts0, kpts1, mkpts0,\n",
    "                            mkpts1, color, text, matches_0, path=None,\n",
    "                            show_keypoints=False, margin=10,\n",
    "                            opencv_display=False, opencv_title='',\n",
    "                            small_text=[]):\n",
    "    H0, W0 = image0.shape\n",
    "    H1, W1 = image1.shape\n",
    "    H, W = max(H0, H1), W0 + W1 + margin\n",
    "\n",
    "    out = 255*np.ones((H, W), np.uint8)\n",
    "    out[:H0, :W0] = image0\n",
    "    out[:H1, W0+margin:] = image1\n",
    "    out = np.stack([out]*3, -1)\n",
    "\n",
    "    if show_keypoints:\n",
    "        kpts0, kpts1 = np.round(kpts0).astype(int), np.round(kpts1).astype(int)\n",
    "        white = (255, 255, 255)\n",
    "        black = (0, 0, 0)\n",
    "        for x, y in kpts0:\n",
    "            cv2.circle(out, (x, y), 2, black, -1, lineType=cv2.LINE_AA)\n",
    "            cv2.circle(out, (x, y), 1, white, -1, lineType=cv2.LINE_AA)\n",
    "        for x, y in kpts1:\n",
    "            cv2.circle(out, (x + margin + W0, y), 2, black, -1,\n",
    "                       lineType=cv2.LINE_AA)\n",
    "            cv2.circle(out, (x + margin + W0, y), 1, white, -1,\n",
    "                       lineType=cv2.LINE_AA)\n",
    "\n",
    "    mkpts0, mkpts1 = np.round(mkpts0).astype(int), np.round(mkpts1).astype(int)\n",
    "    color = (np.array(color[:, :3])*255).astype(int)[:, ::-1]\n",
    "    for (x0, y0), (x1, y1), c, m in zip(mkpts0, mkpts1, color, matches_0):\n",
    "        if m != -1:  # Only draw if the match is valid\n",
    "            c = c.tolist()\n",
    "            cv2.line(out, (x0, y0), (x1 + margin + W0, y1),\n",
    "                    color=c, thickness=1, lineType=cv2.LINE_AA)\n",
    "            # display line end-points as circles\n",
    "            cv2.circle(out, (x0, y0), 2, c, -1, lineType=cv2.LINE_AA)\n",
    "            cv2.circle(out, (x1 + margin + W0, y1), 2, c, -1,\n",
    "                    lineType=cv2.LINE_AA)\n",
    "\n",
    "    # Scale factor for consistent visualization across scales.\n",
    "    sc = min(H / 640., 2.0)\n",
    "\n",
    "    # Big text.\n",
    "    Ht = int(30 * sc)  # text height\n",
    "    txt_color_fg = (255, 255, 255)\n",
    "    txt_color_bg = (0, 0, 0)\n",
    "    for i, t in enumerate(text):\n",
    "        cv2.putText(out, t, (int(8*sc), Ht*(i+1)), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    1.0*sc, txt_color_bg, 2, cv2.LINE_AA)\n",
    "        cv2.putText(out, t, (int(8*sc), Ht*(i+1)), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    1.0*sc, txt_color_fg, 1, cv2.LINE_AA)\n",
    "\n",
    "    # Small text.\n",
    "    Ht = int(18 * sc)  # text height\n",
    "    for i, t in enumerate(reversed(small_text)):\n",
    "        cv2.putText(out, t, (int(8*sc), int(H-Ht*(i+.6))), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    0.5*sc, txt_color_bg, 2, cv2.LINE_AA)\n",
    "        cv2.putText(out, t, (int(8*sc), int(H-Ht*(i+.6))), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    0.5*sc, txt_color_fg, 1, cv2.LINE_AA)\n",
    "\n",
    "    if path is not None:\n",
    "        print(f\"Writing to Path {str(path)}\")\n",
    "        cv2.imwrite(str(path), out)\n",
    "    else:\n",
    "        print(\"Not writing to Path\")\n",
    "\n",
    "    if opencv_display:\n",
    "        print(\"Displaying\")\n",
    "        cv2.imshow(opencv_title, out)\n",
    "        cv2.waitKey(1)\n",
    "    else:\n",
    "        print(\"Not Displaying\")\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fa07f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def run_benchmark(model_to_benchmark, super_glue_input, iterations=10, warm_up=20):\n",
    "    # Warm-up phase\n",
    "    print(\"Warming up...\")\n",
    "    for _ in range(warm_up):\n",
    "        model_to_benchmark(super_glue_input)\n",
    "    \n",
    "    # Benchmark phase\n",
    "    print(f\"Running benchmark for {iterations} iterations...\")\n",
    "    total_time = 0\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        start_time = time.time()\n",
    "        model_to_benchmark(super_glue_input)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        iteration_time = end_time - start_time\n",
    "        total_time += iteration_time\n",
    "    \n",
    "    average_time = total_time / iterations\n",
    "    print(f\"\\nAverage time: {average_time:.6f} seconds\")\n",
    "    print(f\"Total time for {iterations} iterations: {total_time:.6f} seconds\")\n",
    "    \n",
    "    return average_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80886326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def save_data(data, filepath):\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "    \n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Data saved in {filepath}\")\n",
    "\n",
    "def load_data(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8c6f52",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70562486",
   "metadata": {},
   "source": [
    "## CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c48125a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SuperGlue model (\"indoor\" weights)\n"
     ]
    }
   ],
   "source": [
    "super_glue_model = SuperGlue({}).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a8a7ff",
   "metadata": {},
   "source": [
    "### Single execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6566e1b8",
   "metadata": {},
   "source": [
    "Note: on CPU, batch size 2 gives weird results that do not match with results from batch size 1. \n",
    "That's why we use only batch size of 1 for CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41f3f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_matches_bs1_1 = super_glue_model(super_glue_input_bs1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9807c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_matches_bs1_2 = super_glue_model(super_glue_input_bs1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16919568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved in pkl_files/matches/cpu_bs1_1.pkl\n",
      "Data saved in pkl_files/matches/cpu_bs1_2.pkl\n"
     ]
    }
   ],
   "source": [
    "save_data(cpu_matches_bs1_1, 'pkl_files/matches/cpu_bs1_1.pkl')\n",
    "save_data(cpu_matches_bs1_2, 'pkl_files/matches/cpu_bs1_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9812ee00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to Path assets/matches/IMG_9320_IMG_9321_matches_cpu_2000_1080_1920.png\n",
      "Not Displaying\n"
     ]
    }
   ],
   "source": [
    "plot_matches(\n",
    "        img_0= img1,\n",
    "        img_1 = img2,\n",
    "        kpts_0 = super_glue_input_bs1_1['keypoints0'][0],\n",
    "        kpts_1 = super_glue_input_bs1_1['keypoints1'][0],\n",
    "        matches_0 = cpu_matches_bs1_1['matches0'][0],\n",
    "        scores_0 = super_glue_input_bs1_1['scores0'][0],\n",
    "        num_keypoints = NUM_KEYPOINTS,\n",
    "        hardware_type = \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a819f1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to Path assets/matches/IMG_9323_IMG_9324_matches_cpu_2000_1080_1920.png\n",
      "Not Displaying\n"
     ]
    }
   ],
   "source": [
    "plot_matches(\n",
    "        img_0= img3,\n",
    "        img_1 = img4,\n",
    "        kpts_0 = super_glue_input_bs1_2['keypoints0'][0],\n",
    "        kpts_1 = super_glue_input_bs1_2['keypoints1'][0],\n",
    "        matches_0 = cpu_matches_bs1_2['matches0'][0],\n",
    "        scores_0 = super_glue_input_bs1_2['scores0'][0],\n",
    "        num_keypoints = NUM_KEYPOINTS,\n",
    "        hardware_type = \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346ceb72",
   "metadata": {},
   "source": [
    "### Multiple executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6524b645",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_time = run_benchmark(super_glue_model, super_glue_input_bs1_1, iterations=10, warm_up=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37f8a0a",
   "metadata": {},
   "source": [
    "## Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a61493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a neuron library is available\n",
    "try:\n",
    "    import torch_neuronx\n",
    "    neuron_library_available = True\n",
    "except ImportError:\n",
    "    neuron_library_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "addb29ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import torch_neuronx\n",
    "\n",
    "def compile_neuron_model(super_glue_model, super_glue_input, neuron_model_filename, flags=[]):\n",
    "\n",
    "    full_model_path = f'models/{neuron_model_filename}.pt'\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "\n",
    "    compiler_workdir = 'custom_neuron_workdir'\n",
    "    compiler_workdir_path = Path.cwd() / compiler_workdir\n",
    "    if os.path.exists(compiler_workdir_path):\n",
    "        print(f'Clearing compiler dir: {compiler_workdir_path}')\n",
    "        shutil.rmtree(compiler_workdir_path)\n",
    "    print(f'Making compiler dir: {compiler_workdir_path}')\n",
    "    compiler_workdir_path.mkdir(exist_ok=True)\n",
    "    print(f'Setting compiler dir: {compiler_workdir_path.absolute()}')\n",
    "    \n",
    "    if os.path.isfile(full_model_path):\n",
    "        print(f'Pre-Saved Neuron Model File exists at: {full_model_path}')            \n",
    "    else:\n",
    "        print(\"Pre-Saved Neuron Model File does not exist. Compiling it\")\n",
    "\n",
    "        print(\"Clearing neuron cache\")\n",
    "        cache_path = \"/var/tmp/neuron-compile-cache\"\n",
    "        try:\n",
    "            if os.path.exists(cache_path):\n",
    "                shutil.rmtree(cache_path)\n",
    "                print(f\"Successfully removed {cache_path}\")\n",
    "            else:\n",
    "                print(f\"Folder {cache_path} does not exist\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error removing {cache_path}: {e}\")\n",
    "\n",
    "        print(f'Compiling with flags: {flags}')\n",
    "        neuron_traced_super_glue_model = torch_neuronx.trace(super_glue_model, super_glue_input, compiler_args=flags, compiler_workdir=compiler_workdir_path.absolute())\n",
    "        torch.jit.save(neuron_traced_super_glue_model, full_model_path)\n",
    "\n",
    "    return torch.jit.load(full_model_path)\n",
    "\n",
    "\n",
    "def create_random_inputs(nb_keypoints=1000, image_size=(1920, 1080)):\n",
    "    \"\"\"\n",
    "    Create random inputs for testing the neuron model.\n",
    "    \n",
    "    Args:\n",
    "        nb_keypoints: Number of keypoints to generate\n",
    "        image_size: Size of the images (height, width)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Randomly generated inputs\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'keypoints0': torch.rand((1, nb_keypoints, 2)),\n",
    "        'keypoints1': torch.rand((1, nb_keypoints, 2)),\n",
    "        'descriptors0':  torch.rand((1, 256, nb_keypoints)),\n",
    "        'descriptors1':  torch.rand((1, 256, nb_keypoints)),\n",
    "        'scores0':  torch.rand((1, nb_keypoints)),\n",
    "        'scores1':  torch.rand((1, nb_keypoints)),\n",
    "        'image0': torch.rand((1, 1, *image_size)),\n",
    "        'image1': torch.rand((1, 1, *image_size))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25d6accd",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_inputs = create_random_inputs(nb_keypoints=NUM_KEYPOINTS, image_size=img1[\"image\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4758735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flags_to_filename_string(flags):\n",
    "    \"\"\"\n",
    "    Convert a list of flags to a filename-friendly string.\n",
    "    \n",
    "    Args:\n",
    "    flags (list): List of flag strings.\n",
    "    \n",
    "    Returns:\n",
    "    str: A filename-friendly string representation of the flags.\n",
    "    \"\"\"\n",
    "    # Remove leading dashes and replace remaining dashes with underscores\n",
    "    processed_flags = [flag.lstrip('-').replace('-', '_') for flag in flags]\n",
    "    \n",
    "    # Join the processed flags with underscores\n",
    "    filename_string = '_'.join(processed_flags)\n",
    "    \n",
    "    # Replace '=' with '_' to avoid issues in some file systems\n",
    "    filename_string = filename_string.replace('=', '_')\n",
    "    \n",
    "    return filename_string    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "440f1340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making compiler dir: /home/ubuntu/superglue-neuron/custom_neuron_workdir\n",
      "Setting compiler dir: /home/ubuntu/superglue-neuron/custom_neuron_workdir\n",
      "Pre-Saved Neuron Model File does not exist. Compiling it\n",
      "Clearing neuron cache\n",
      "Folder /var/tmp/neuron-compile-cache does not exist\n",
      "Compiling with flags: ['--auto-cast=none', '--model-type=unet-inference']\n",
      "2025-07-10 10:39:49.000271:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/bce750bc-8337-4a11-b065-6466159dedd6/model.MODULE_10682217524436566897+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/bce750bc-8337-4a11-b065-6466159dedd6/model.MODULE_10682217524436566897+e30acd3a.neff --target=trn1 --verbose=35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.10/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:289: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=6, shape=torch.Size([1, 1, 1080, 1920]), dtype=torch.float32)\n",
      "  warnings.warn(\n",
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.10/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:289: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=7, shape=torch.Size([1, 1, 1080, 1920]), dtype=torch.float32)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:39:53.000135:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/a19ce7f0-e366-49de-8636-6a27435ce448/model.MODULE_15164771439026754743+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/a19ce7f0-e366-49de-8636-6a27435ce448/model.MODULE_15164771439026754743+e30acd3a.neff --target=trn1 --verbose=35\n",
      ".Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:39:56.000508:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/55fe9259-361e-4784-86bd-a3b0db9d7532/model.MODULE_3625415799110469568+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/55fe9259-361e-4784-86bd-a3b0db9d7532/model.MODULE_3625415799110469568+e30acd3a.neff --target=trn1 --verbose=35\n",
      ".Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:39:58.000997:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/e5a9104e-cc8d-4868-8273-79e756e39524/model.MODULE_16655694682498058249+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/e5a9104e-cc8d-4868-8273-79e756e39524/model.MODULE_16655694682498058249+e30acd3a.neff --target=trn1 --verbose=35\n",
      ".Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:40:02.000734:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/91f430c5-090e-42a9-bc73-727d7bfe37bd/model.MODULE_13279684627762665035+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/91f430c5-090e-42a9-bc73-727d7bfe37bd/model.MODULE_13279684627762665035+e30acd3a.neff --target=trn1 --verbose=35\n",
      ".Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:40:06.000281:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/174cd892-6c7d-43ea-9788-19fa2552c4d3/model.MODULE_11888526262673322839+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/174cd892-6c7d-43ea-9788-19fa2552c4d3/model.MODULE_11888526262673322839+e30acd3a.neff --target=trn1 --verbose=35\n",
      ".Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:40:10.000424:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/a768ee5d-9732-4bb1-b8ae-dd131c3e28ff/model.MODULE_8485106387103381173+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/a768ee5d-9732-4bb1-b8ae-dd131c3e28ff/model.MODULE_8485106387103381173+e30acd3a.neff --target=trn1 --verbose=35\n",
      ".Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:40:14.000345:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/e78ff892-bda6-4a19-ac1f-144c3c645445/model.MODULE_7648355112781281659+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/e78ff892-bda6-4a19-ac1f-144c3c645445/model.MODULE_7648355112781281659+e30acd3a.neff --target=trn1 --verbose=35\n",
      ".Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:40:18.000923:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/8105bac9-5ab8-4e34-9880-f1666cf3760a/model.MODULE_1292263853741936371+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/8105bac9-5ab8-4e34-9880-f1666cf3760a/model.MODULE_1292263853741936371+e30acd3a.neff --target=trn1 --verbose=35\n",
      ".Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:40:23.000435:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/310de96e-05f6-445d-b933-2eadc1c280e2/model.MODULE_6375514057080320127+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/310de96e-05f6-445d-b933-2eadc1c280e2/model.MODULE_6375514057080320127+e30acd3a.neff --target=trn1 --verbose=35\n",
      ".Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:40:34.000461:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/44449965-92e7-4b93-b539-046e14aa8814/model.MODULE_3988085349799719347+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/44449965-92e7-4b93-b539-046e14aa8814/model.MODULE_3988085349799719347+e30acd3a.neff --target=trn1 --verbose=35\n",
      ".Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:40:45.000369:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/49506bda-aca3-4dea-9525-2a226f5c5ad2/model.MODULE_2663855534165129321+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/49506bda-aca3-4dea-9525-2a226f5c5ad2/model.MODULE_2663855534165129321+e30acd3a.neff --target=trn1 --verbose=35\n",
      ".Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:41:03.000273:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/b43b6e14-b753-43de-98be-f471c1cebc18/model.MODULE_1672978686308119454+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/b43b6e14-b753-43de-98be-f471c1cebc18/model.MODULE_1672978686308119454+e30acd3a.neff --target=trn1 --verbose=35\n",
      ".Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:41:20.000534:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/53097dc8-39dd-42e9-b3fc-e025e08b5077/model.MODULE_2138020752942790486+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/53097dc8-39dd-42e9-b3fc-e025e08b5077/model.MODULE_2138020752942790486+e30acd3a.neff --target=trn1 --verbose=35\n",
      "..Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:41:44.000693:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/112f7504-a46e-41de-a211-1eda12642389/model.MODULE_1743754106294518871+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/112f7504-a46e-41de-a211-1eda12642389/model.MODULE_1743754106294518871+e30acd3a.neff --target=trn1 --verbose=35\n",
      "..Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:42:09.000006:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/9cb4a197-0c13-49d6-b626-62b212bb9686/model.MODULE_9502623241265766003+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/9cb4a197-0c13-49d6-b626-62b212bb9686/model.MODULE_9502623241265766003+e30acd3a.neff --target=trn1 --verbose=35\n",
      "..Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:42:40.000313:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/5731333a-36de-4899-a364-ed4d4b02b40d/model.MODULE_11101032052922196359+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/5731333a-36de-4899-a364-ed4d4b02b40d/model.MODULE_11101032052922196359+e30acd3a.neff --target=trn1 --verbose=35\n",
      "..Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:43:13.000592:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/1743c844-38bf-48ec-af6c-e068cb5ed890/model.MODULE_10890223333705001876+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/1743c844-38bf-48ec-af6c-e068cb5ed890/model.MODULE_10890223333705001876+e30acd3a.neff --target=trn1 --verbose=35\n",
      "..Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:43:52.000297:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/c04332c5-2259-439b-90b3-ce630cc193bc/model.MODULE_14431564086847915732+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/c04332c5-2259-439b-90b3-ce630cc193bc/model.MODULE_14431564086847915732+e30acd3a.neff --target=trn1 --verbose=35\n",
      "..Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:44:30.000956:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/03d83040-b8e2-4614-83e3-d2c71ff4d6dc/model.MODULE_15920251077849722886+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/03d83040-b8e2-4614-83e3-d2c71ff4d6dc/model.MODULE_15920251077849722886+e30acd3a.neff --target=trn1 --verbose=35\n",
      "...Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:45:16.000502:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/956c17e3-8056-4c67-8866-4353f4c7743c/model.MODULE_6034910032109310799+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/956c17e3-8056-4c67-8866-4353f4c7743c/model.MODULE_6034910032109310799+e30acd3a.neff --target=trn1 --verbose=35\n",
      "...Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:46:01.000518:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/3ad720ba-854f-47f5-92aa-ebdd959d3a54/model.MODULE_9642468604386795547+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/3ad720ba-854f-47f5-92aa-ebdd959d3a54/model.MODULE_9642468604386795547+e30acd3a.neff --target=trn1 --verbose=35\n",
      "...Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:46:58.000247:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/a038350e-8cde-4346-a940-e1447cca3382/model.MODULE_5354674298182493578+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/a038350e-8cde-4346-a940-e1447cca3382/model.MODULE_5354674298182493578+e30acd3a.neff --target=trn1 --verbose=35\n",
      "...Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:47:51.000167:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/55160239-085f-4da3-b918-6e904d9e9ac3/model.MODULE_16749898825123779897+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/55160239-085f-4da3-b918-6e904d9e9ac3/model.MODULE_16749898825123779897+e30acd3a.neff --target=trn1 --verbose=35\n",
      "...Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:48:50.000222:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/4a8ec84c-aadb-4353-b8a1-a1065c036a84/model.MODULE_13123080765444268537+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/4a8ec84c-aadb-4353-b8a1-a1065c036a84/model.MODULE_13123080765444268537+e30acd3a.neff --target=trn1 --verbose=35\n",
      "...Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:49:49.000190:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/6f15a80e-0959-405c-889b-0d84ed06c3c1/model.MODULE_3616206536810912602+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/6f15a80e-0959-405c-889b-0d84ed06c3c1/model.MODULE_3616206536810912602+e30acd3a.neff --target=trn1 --verbose=35\n",
      "....Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:50:55.000879:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/3d9f154c-171e-43f5-be3b-6b762bbfe156/model.MODULE_17527567761735731958+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/3d9f154c-171e-43f5-be3b-6b762bbfe156/model.MODULE_17527567761735731958+e30acd3a.neff --target=trn1 --verbose=35\n",
      "....Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:52:02.000806:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/5baec2c8-1625-4e77-ba33-7b01ddfba418/model.MODULE_1396643415369958636+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/5baec2c8-1625-4e77-ba33-7b01ddfba418/model.MODULE_1396643415369958636+e30acd3a.neff --target=trn1 --verbose=35\n",
      "....Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:53:16.000699:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/4defe935-36f8-4f40-8334-ee12980b4fa7/model.MODULE_15717646178247669478+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/4defe935-36f8-4f40-8334-ee12980b4fa7/model.MODULE_15717646178247669478+e30acd3a.neff --target=trn1 --verbose=35\n",
      "....Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:54:29.000952:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/b2bed6bc-8827-4ca7-a1db-36fc550f8bee/model.MODULE_11148485954491932652+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/b2bed6bc-8827-4ca7-a1db-36fc550f8bee/model.MODULE_11148485954491932652+e30acd3a.neff --target=trn1 --verbose=35\n",
      "....Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:55:50.000426:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/4c411ea1-ea89-44f7-87ae-43c91d9d9a38/model.MODULE_9071746696014300943+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/4c411ea1-ea89-44f7-87ae-43c91d9d9a38/model.MODULE_9071746696014300943+e30acd3a.neff --target=trn1 --verbose=35\n",
      ".....Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:57:11.000382:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/54c93988-d72c-4a1a-a7ba-b7824f8eb0f0/model.MODULE_7462346331713133491+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/54c93988-d72c-4a1a-a7ba-b7824f8eb0f0/model.MODULE_7462346331713133491+e30acd3a.neff --target=trn1 --verbose=35\n",
      ".....Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 10:58:39.000791:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/baa47e68-0482-4420-94b9-0ab251793477/model.MODULE_16604211619118092593+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/baa47e68-0482-4420-94b9-0ab251793477/model.MODULE_16604211619118092593+e30acd3a.neff --target=trn1 --verbose=35\n",
      ".....Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 11:00:08.000857:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/766d3987-aee7-4493-9a86-94f39a60b361/model.MODULE_15081073964148600464+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/766d3987-aee7-4493-9a86-94f39a60b361/model.MODULE_15081073964148600464+e30acd3a.neff --target=trn1 --verbose=35\n",
      ".....Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 11:01:43.000545:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/4befb509-dd28-4425-8b29-d2084828d648/model.MODULE_15380171636348180379+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/4befb509-dd28-4425-8b29-d2084828d648/model.MODULE_15380171636348180379+e30acd3a.neff --target=trn1 --verbose=35\n",
      ".....Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 11:03:19.000787:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/1583d7e3-4840-4ae9-9249-0474e1754cc7/model.MODULE_11452455381711619613+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/1583d7e3-4840-4ae9-9249-0474e1754cc7/model.MODULE_11452455381711619613+e30acd3a.neff --target=trn1 --verbose=35\n",
      "......Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 11:05:02.000734:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/e68d3217-ba41-4597-9bdb-c3d334353159/model.MODULE_17756848726986680305+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/e68d3217-ba41-4597-9bdb-c3d334353159/model.MODULE_17756848726986680305+e30acd3a.neff --target=trn1 --verbose=35\n",
      "......Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 11:06:44.000902:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/5ecb40c2-dbdb-44b7-a3af-a7d08fa56c84/model.MODULE_3457790708568314807+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/5ecb40c2-dbdb-44b7-a3af-a7d08fa56c84/model.MODULE_3457790708568314807+e30acd3a.neff --target=trn1 --verbose=35\n",
      "......Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 11:08:34.000879:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/426f406f-d04d-4ec4-b919-94cb6d831f12/model.MODULE_14768643876625366820+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/426f406f-d04d-4ec4-b919-94cb6d831f12/model.MODULE_14768643876625366820+e30acd3a.neff --target=trn1 --verbose=35\n",
      "......Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 11:10:24.000556:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/bd5903f8-3b19-447d-b82d-c38b0ad5ca6d/model.MODULE_12055202283739520425+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/bd5903f8-3b19-447d-b82d-c38b0ad5ca6d/model.MODULE_12055202283739520425+e30acd3a.neff --target=trn1 --verbose=35\n",
      "......Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 11:12:21.000254:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/f8c71a79-aca3-409d-b437-d9eecda384d0/model.MODULE_8185609678593817491+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/f8c71a79-aca3-409d-b437-d9eecda384d0/model.MODULE_8185609678593817491+e30acd3a.neff --target=trn1 --verbose=35\n",
      "......Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 11:14:17.000751:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/95296fd9-71f6-4a3a-8b1a-ba7e84f8ab21/model.MODULE_6974808041058308014+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/95296fd9-71f6-4a3a-8b1a-ba7e84f8ab21/model.MODULE_6974808041058308014+e30acd3a.neff --target=trn1 --verbose=35\n",
      ".......Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 11:16:22.000988:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/6461c705-98bb-4c34-b10e-348d5110c694/model.MODULE_5958005100591712324+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/6461c705-98bb-4c34-b10e-348d5110c694/model.MODULE_5958005100591712324+e30acd3a.neff --target=trn1 --verbose=35\n",
      ".......Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 11:18:28.000456:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/22d0dbc2-b00a-4335-bd41-b360fda285d0/model.MODULE_8097499046981096262+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/22d0dbc2-b00a-4335-bd41-b360fda285d0/model.MODULE_8097499046981096262+e30acd3a.neff --target=trn1 --verbose=35\n",
      ".......Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "2025-07-10 11:20:41.000983:  8518  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/9ea59f58-8f9b-4dd0-a0cf-43a55f9047e6/model.MODULE_851691754066235267+e30acd3a.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/9ea59f58-8f9b-4dd0-a0cf-43a55f9047e6/model.MODULE_851691754066235267+e30acd3a.neff --target=trn1 --verbose=35\n",
      ".......Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n",
      "...............Completed run_backend_driver.\n",
      "\n",
      "Compiler status PASS\n"
     ]
    }
   ],
   "source": [
    "flags = ['--auto-cast=none', '--model-type=unet-inference']\n",
    "#flags = ['--auto-cast=none', '--model-type=generic']\n",
    "if neuron_library_available:\n",
    "    neuron_model = compile_neuron_model(super_glue_model, random_inputs, f\"neuron_model_fp32_{NUM_KEYPOINTS}_{img1['image'].shape[0]}_{img1['image'].shape[1]}_{flags_to_filename_string(flags)}\", flags= flags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854add36",
   "metadata": {},
   "source": [
    "### Batch size 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d36c218",
   "metadata": {},
   "source": [
    "#### Single execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c047091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved in pkl_files/matches/neuron_bs1_1.pkl\n",
      "Data saved in pkl_files/matches/neuron_bs1_2.pkl\n"
     ]
    }
   ],
   "source": [
    "if neuron_library_available:\n",
    "    neuron_matches_bs1_1 = neuron_model(super_glue_input_bs1_1)\n",
    "    save_data(neuron_matches_bs1_1, 'pkl_files/matches/neuron_bs1_1.pkl')\n",
    "    neuron_matches_bs1_2 = neuron_model(super_glue_input_bs1_2)\n",
    "    save_data(neuron_matches_bs1_2, 'pkl_files/matches/neuron_bs1_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f27a3ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to Path assets/matches/IMG_9320_IMG_9321_matches_neuron_bs1_1_2000_1080_1920.png\n",
      "Not Displaying\n",
      "Writing to Path assets/matches/IMG_9323_IMG_9324_matches_neuron_bs1_2_2000_1080_1920.png\n",
      "Not Displaying\n"
     ]
    }
   ],
   "source": [
    "plot_matches(\n",
    "        img_0= img1,\n",
    "        img_1 = img2,\n",
    "        kpts_0 = super_glue_input_bs1_1['keypoints0'][0],\n",
    "        kpts_1 = super_glue_input_bs1_1['keypoints1'][0],\n",
    "        matches_0 = neuron_matches_bs1_1['matches0'][0],\n",
    "        scores_0 = super_glue_input_bs1_1['scores0'][0],\n",
    "        num_keypoints = NUM_KEYPOINTS,\n",
    "        hardware_type = \"neuron_bs1_1\"\n",
    ")\n",
    "\n",
    "plot_matches(\n",
    "        img_0= img3,\n",
    "        img_1 = img4,\n",
    "        kpts_0 = super_glue_input_bs1_2['keypoints0'][0],\n",
    "        kpts_1 = super_glue_input_bs1_2['keypoints1'][0],\n",
    "        matches_0 = neuron_matches_bs1_2['matches0'][0],\n",
    "        scores_0 = super_glue_input_bs1_2['scores0'][0],\n",
    "        num_keypoints = NUM_KEYPOINTS,\n",
    "        hardware_type = \"neuron_bs1_2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591bc272",
   "metadata": {},
   "source": [
    "#### Multiple executions - benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f03d9f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up...\n",
      "Running benchmark for 100 iterations...\n",
      "\n",
      "Average time: 0.061135 seconds\n",
      "Total time for 100 iterations: 6.113550 seconds\n"
     ]
    }
   ],
   "source": [
    "if neuron_library_available:\n",
    "    average_time = run_benchmark(neuron_model, super_glue_input_bs1_1, iterations=100, warm_up=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53af347a",
   "metadata": {},
   "source": [
    "### Batch size 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "063c4f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DataParallel\n"
     ]
    }
   ],
   "source": [
    "if neuron_library_available:\n",
    "    print(\"Using DataParallel\")\n",
    "    neuron_model = torch_neuronx.DataParallel(neuron_model, set_dynamic_batching=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2265cc3",
   "metadata": {},
   "source": [
    "#### Single execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ce4ad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if neuron_library_available:\n",
    "    neuron_matches_bs2 = neuron_model(super_glue_input_bs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "399b6384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved in pkl_files/matches/neuron_bs2.pkl\n"
     ]
    }
   ],
   "source": [
    "save_data(neuron_matches_bs2, 'pkl_files/matches/neuron_bs2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "916d1895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to Path assets/matches/IMG_9320_IMG_9321_matches_neuron_bs2_1_2000_1080_1920.png\n",
      "Not Displaying\n"
     ]
    }
   ],
   "source": [
    "plot_matches(\n",
    "        img_0= img1,\n",
    "        img_1 = img2,\n",
    "        kpts_0 = super_glue_input_bs2['keypoints0'][0],\n",
    "        kpts_1 = super_glue_input_bs2['keypoints1'][0],\n",
    "        matches_0 = neuron_matches_bs2['matches0'][0],\n",
    "        scores_0 = super_glue_input_bs2['scores0'][0],\n",
    "        num_keypoints = NUM_KEYPOINTS,\n",
    "        hardware_type = \"neuron_bs2_1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65a1b698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to Path assets/matches/IMG_9323_IMG_9324_matches_neuron_bs2_2_2000_1080_1920.png\n",
      "Not Displaying\n"
     ]
    }
   ],
   "source": [
    "plot_matches(\n",
    "        img_0= img3,\n",
    "        img_1 = img4,\n",
    "        kpts_0 = super_glue_input_bs2['keypoints0'][1],\n",
    "        kpts_1 = super_glue_input_bs2['keypoints1'][1],\n",
    "        matches_0 = neuron_matches_bs2['matches0'][1],\n",
    "        scores_0 = super_glue_input_bs2['scores0'][1],\n",
    "        num_keypoints = NUM_KEYPOINTS,\n",
    "        hardware_type = \"neuron_bs2_2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409ac850",
   "metadata": {},
   "source": [
    "#### Multiple executions - benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4da8b55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up...\n",
      "Running benchmark for 100 iterations...\n",
      "\n",
      "Average time: 0.074402 seconds\n",
      "Total time for 100 iterations: 7.440212 seconds\n"
     ]
    }
   ],
   "source": [
    "if neuron_library_available:\n",
    "    average_time = run_benchmark(neuron_model, super_glue_input_bs2, iterations=100, warm_up=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6831a3",
   "metadata": {},
   "source": [
    "# Sanity check - outputs comparison (CPU vs Neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "369c99e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_tensor_dicts(dict1, dict2, atol=1e-8):\n",
    "    \"\"\"\n",
    "    Compare two dictionaries containing tensors with tolerance for small differences.\n",
    "    \n",
    "    Args:\n",
    "        dict1, dict2: Dictionaries to compare\n",
    "        atol: Absolute tolerance\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with comparison results for each key\n",
    "    \"\"\"\n",
    "    if dict1.keys() != dict2.keys():\n",
    "        return {\"keys_match\": False, \"missing_keys\": set(dict1.keys()) ^ set(dict2.keys())}\n",
    "    \n",
    "    results = {\"keys_match\": True, \"all_close\": True, \"details\": {}}\n",
    "    \n",
    "    for key in dict1:\n",
    "        if not isinstance(dict1[key], torch.Tensor) or not isinstance(dict2[key], torch.Tensor):\n",
    "            results[\"details\"][key] = {\n",
    "                \"close\": dict1[key] == dict2[key],\n",
    "                \"error\": \"Not tensors\"\n",
    "            }\n",
    "            if dict1[key] != dict2[key]:\n",
    "                results[\"all_close\"] = False\n",
    "            continue\n",
    "            \n",
    "        # Check shapes first\n",
    "        if dict1[key].shape != dict2[key].shape:\n",
    "            results[\"details\"][key] = {\n",
    "                \"close\": False,\n",
    "                \"error\": f\"Shape mismatch: {dict1[key].shape} vs {dict2[key].shape}\"\n",
    "            }\n",
    "            results[\"all_close\"] = False\n",
    "            continue\n",
    "        \n",
    "        # Check values with tolerance\n",
    "        is_close = torch.allclose(dict1[key], dict2[key], atol=atol)\n",
    "        \n",
    "        if not is_close:\n",
    "            # Calculate differences for detailed reporting\n",
    "            abs_diff = (dict1[key] - dict2[key]).abs()\n",
    "            max_diff = abs_diff.max().item()\n",
    "            mean_diff = abs_diff.mean(dtype=torch.float).item()  # Specify dtype=torch.float\n",
    "            \n",
    "            # Collate all indices where the values are different\n",
    "            diff_indices = torch.nonzero(abs_diff > atol, as_tuple=False)\n",
    "            diff_values = []\n",
    "            for idx in diff_indices:\n",
    "                # Convert index to tuple for multi-dimensional tensors\n",
    "                idx_tuple = tuple(idx.tolist())\n",
    "                val1 = dict1[key][idx_tuple].item()\n",
    "                val2 = dict2[key][idx_tuple].item()\n",
    "                diff = abs(val1 - val2)\n",
    "                diff_values.append({\n",
    "                    \"index\": idx_tuple,\n",
    "                    \"value1\": val1,\n",
    "                    \"value2\": val2,\n",
    "                    \"diff\": diff\n",
    "                })\n",
    "\n",
    "            results[\"details\"][key] = {\n",
    "                \"close\": False,\n",
    "                \"max_diff\": max_diff,\n",
    "                \"mean_diff\": mean_diff,\n",
    "                \"max_diff_index\": abs_diff.argmax().item() if abs_diff.numel() > 0 else None,\n",
    "                \"diff_count\": len(diff_indices),\n",
    "                \"total_count\": len(abs_diff[0]),\n",
    "                \"diff_values\": diff_values[:10]  # Limit to first 10 differences to avoid huge outputs\n",
    "            }\n",
    "\n",
    "            results[\"all_close\"] = False\n",
    "        else:\n",
    "            results[\"details\"][key] = {\"close\": True}\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a7b1552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all_close': False,\n",
      " 'details': {'matches0': {'close': True},\n",
      "             'matches1': {'close': True},\n",
      "             'matching_scores0': {'close': False,\n",
      "                                  'diff_count': 1,\n",
      "                                  'diff_values': [{'diff': 0.0004196465015411377,\n",
      "                                                   'index': (0, 355),\n",
      "                                                   'value1': 0.462631493806839,\n",
      "                                                   'value2': 0.46221184730529785}],\n",
      "                                  'max_diff': 0.0004196465015411377,\n",
      "                                  'max_diff_index': 355,\n",
      "                                  'mean_diff': 2.8205802209413378e-06,\n",
      "                                  'total_count': 2000},\n",
      "             'matching_scores1': {'close': False,\n",
      "                                  'diff_count': 1,\n",
      "                                  'diff_values': [{'diff': 0.0004196465015411377,\n",
      "                                                   'index': (0, 523),\n",
      "                                                   'value1': 0.462631493806839,\n",
      "                                                   'value2': 0.46221184730529785}],\n",
      "                                  'max_diff': 0.0004196465015411377,\n",
      "                                  'max_diff_index': 523,\n",
      "                                  'mean_diff': 2.8205802209413378e-06,\n",
      "                                  'total_count': 2000}},\n",
      " 'keys_match': True}\n"
     ]
    }
   ],
   "source": [
    "if neuron_library_available:\n",
    "    comparison_of_original_model_vs_neuron = compare_tensor_dicts(cpu_matches_bs1_1, neuron_matches_bs1_1, 1e-4)\n",
    "    pprint.pprint(comparison_of_original_model_vs_neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d0d1a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all_close': True,\n",
      " 'details': {'matches0': {'close': True},\n",
      "             'matches1': {'close': True},\n",
      "             'matching_scores0': {'close': True},\n",
      "             'matching_scores1': {'close': True}},\n",
      " 'keys_match': True}\n"
     ]
    }
   ],
   "source": [
    "if neuron_library_available:\n",
    "    comparison_of_original_model_vs_neuron = compare_tensor_dicts(cpu_matches_bs1_2, neuron_matches_bs1_2, 1e-4)\n",
    "    pprint.pprint(comparison_of_original_model_vs_neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cbc119a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all_close': True,\n",
      " 'details': {'matches0': {'close': True},\n",
      "             'matches1': {'close': True},\n",
      "             'matching_scores0': {'close': True},\n",
      "             'matching_scores1': {'close': True}},\n",
      " 'keys_match': True}\n"
     ]
    }
   ],
   "source": [
    "# concatenating batch size 1 tensors to compare with batch size 2 tensor\n",
    "contat_tensors_bs1 = {\n",
    "    \"matches0\": torch.cat([neuron_matches_bs1_1[\"matches0\"],neuron_matches_bs1_2[\"matches0\"]],dim=0),\n",
    "    \"matches1\": torch.cat([neuron_matches_bs1_1[\"matches1\"],neuron_matches_bs1_2[\"matches1\"]],dim=0),\n",
    "    \"matching_scores0\": torch.cat([neuron_matches_bs1_1[\"matching_scores0\"],neuron_matches_bs1_2[\"matching_scores0\"]],dim=0),\n",
    "    \"matching_scores1\": torch.cat([neuron_matches_bs1_1[\"matching_scores1\"],neuron_matches_bs1_2[\"matching_scores1\"]],dim=0),\n",
    "}\n",
    "\n",
    "if neuron_library_available:\n",
    "    comparison_of_original_model_vs_neuron = compare_tensor_dicts(contat_tensors_bs1, neuron_matches_bs2, 1e-4)\n",
    "    pprint.pprint(comparison_of_original_model_vs_neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d0e325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile the neuron model\n",
    "!neuron-profile capture --enable-dge-notifs -n custom_neuron_workdir/graph.neff -s profile.ntff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuron_venv_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
